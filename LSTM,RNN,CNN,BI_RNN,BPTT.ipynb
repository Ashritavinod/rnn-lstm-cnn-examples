{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **LSTM**"
      ],
      "metadata": {
        "id": "N7uMNyH_Wk_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "q-zZ-nC-Zhyl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a simple sine wave sequence for training\n",
        "def generate_data(seq_length):\n",
        "    x = np.linspace(0, 2 * np.pi, seq_length)\n",
        "    data = np.sin(x)\n",
        "    return data\n",
        "\n",
        "sequence_length = 50\n",
        "data = generate_data(sequence_length + 1)\n",
        "\n",
        "# Prepare input and target\n",
        "x = torch.tensor(data[:-1], dtype=torch.float32).reshape(1, sequence_length, 1)\n",
        "y = torch.tensor(data[1:], dtype=torch.float32).reshape(1, sequence_length, 1)\n"
      ],
      "metadata": {
        "id": "tYq9nTOgZlNi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=50, num_layers=1, output_size=1):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "Z4Lk-pbGZqOt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMModel()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "epochs = 200\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    output = model(x)\n",
        "    loss = criterion(output, y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evBLCh7OZtQh",
        "outputId": "65d5b466-8d96-4e6d-a349-4d0b7eda03ab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/200], Loss: 0.0046\n",
            "Epoch [40/200], Loss: 0.0008\n",
            "Epoch [60/200], Loss: 0.0001\n",
            "Epoch [80/200], Loss: 0.0000\n",
            "Epoch [100/200], Loss: 0.0000\n",
            "Epoch [120/200], Loss: 0.0000\n",
            "Epoch [140/200], Loss: 0.0000\n",
            "Epoch [160/200], Loss: 0.0000\n",
            "Epoch [180/200], Loss: 0.0000\n",
            "Epoch [200/200], Loss: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RNN**"
      ],
      "metadata": {
        "id": "PCp1DuR2W3Ds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "4I0ZikM1aHgW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data(seq_length):\n",
        "    x = np.linspace(0, 2 * np.pi, seq_length)\n",
        "    data = np.sin(x)\n",
        "    return data\n",
        "\n",
        "sequence_length = 50\n",
        "data = generate_data(sequence_length + 1)\n",
        "\n",
        "# Prepare input and target tensors\n",
        "x = torch.tensor(data[:-1], dtype=torch.float32).reshape(1, sequence_length, 1)  # shape: (batch, seq_len, input_size)\n",
        "y = torch.tensor(data[1:], dtype=torch.float32).reshape(1, sequence_length, 1)  # shifted target\n"
      ],
      "metadata": {
        "id": "mq4mJGK0abO3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=50, num_layers=1, output_size=1):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = self.fc(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "0QLUQvr7af9q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNNModel()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "epochs = 200\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    output = model(x)\n",
        "    loss = criterion(output, y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9j_N8mxxajIr",
        "outputId": "f5521c39-f115-4661-9e5f-7ff18593cfb5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/200], Loss: 0.0028\n",
            "Epoch [40/200], Loss: 0.0005\n",
            "Epoch [60/200], Loss: 0.0001\n",
            "Epoch [80/200], Loss: 0.0000\n",
            "Epoch [100/200], Loss: 0.0000\n",
            "Epoch [120/200], Loss: 0.0000\n",
            "Epoch [140/200], Loss: 0.0000\n",
            "Epoch [160/200], Loss: 0.0000\n",
            "Epoch [180/200], Loss: 0.0000\n",
            "Epoch [200/200], Loss: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CNN**"
      ],
      "metadata": {
        "id": "BEkZOsG-W99v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "UMBrKqKdbF7Z"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform to Tensor and normalize\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Download training and test datasets\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform)\n",
        "\n",
        "# Data loaders\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "GdDs7PlTbGiJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.fc = nn.Linear(32 * 7 * 7, 10)  # 28x28 → 14x14 → 7x7\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0), -1)  # Flatten\n",
        "        out = self.fc(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "HpX3Qs6PbKRh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    for images, labels in train_loader:\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaTpDRsObNTl",
        "outputId": "fd270b54-f1cc-4659-98b7-b26bd1602db9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.0064\n",
            "Epoch [2/5], Loss: 0.0781\n",
            "Epoch [3/5], Loss: 0.0533\n",
            "Epoch [4/5], Loss: 0.0117\n",
            "Epoch [5/5], Loss: 0.1525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BI-RNN**"
      ],
      "metadata": {
        "id": "uRh3NAdRXHsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "_FsKRaAXcD-f"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data(seq_length):\n",
        "    x = np.linspace(0, 2 * np.pi, seq_length)\n",
        "    data = np.sin(x)\n",
        "    return data\n",
        "\n",
        "sequence_length = 50\n",
        "data = generate_data(sequence_length + 1)\n",
        "\n",
        "# Input and target\n",
        "x = torch.tensor(data[:-1], dtype=torch.float32).reshape(1, sequence_length, 1)  # (batch, seq_len, input_size)\n",
        "y = torch.tensor(data[1:], dtype=torch.float32).reshape(1, sequence_length, 1)\n"
      ],
      "metadata": {
        "id": "z5IFstAEcMi1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BiRNNModel(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=64, num_layers=1, output_size=1):\n",
        "        super(BiRNNModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # bidirectional=True\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_size * 2, output_size)  # hidden_size * 2 because of both directions\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size)  # 2 for bidirectional\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = self.fc(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "RW1DBOI-cOz5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BiRNNModel(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=64, num_layers=1, output_size=1):\n",
        "        super(BiRNNModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # bidirectional=True\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_size * 2, output_size)  # hidden_size * 2 because of both directions\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size)  # 2 for bidirectional\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = self.fc(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "A0UdgCHZcRDl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BiRNNModel()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "epochs = 200\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    output = model(x)\n",
        "    loss = criterion(output, y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_I5yye2cTLV",
        "outputId": "a7c73c06-fa93-42a6-ff33-abbfe562b20b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/200], Loss: 0.0048\n",
            "Epoch [40/200], Loss: 0.0015\n",
            "Epoch [60/200], Loss: 0.0003\n",
            "Epoch [80/200], Loss: 0.0002\n",
            "Epoch [100/200], Loss: 0.0001\n",
            "Epoch [120/200], Loss: 0.0001\n",
            "Epoch [140/200], Loss: 0.0001\n",
            "Epoch [160/200], Loss: 0.0000\n",
            "Epoch [180/200], Loss: 0.0000\n",
            "Epoch [200/200], Loss: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BPTT**"
      ],
      "metadata": {
        "id": "zysvudNDXOhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "YOLpDa8ZcamG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's predict the next value in this toy sequence\n",
        "seq = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "x = torch.tensor(seq[:-1], dtype=torch.float32).view(-1, 1)  # Inputs: [0.1, 0.2, 0.3, 0.4]\n",
        "y = torch.tensor(seq[1:], dtype=torch.float32).view(-1, 1)  # Targets: [0.2, 0.3, 0.4, 0.5]\n"
      ],
      "metadata": {
        "id": "TfDhb5eecpUb"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNCell:\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        self.Wx = torch.randn(input_size, hidden_size, requires_grad=True)\n",
        "        self.Wh = torch.randn(hidden_size, hidden_size, requires_grad=True)\n",
        "        self.b = torch.zeros(hidden_size, requires_grad=True)\n",
        "        self.Wy = torch.randn(hidden_size, 1, requires_grad=True)\n",
        "        self.by = torch.zeros(1, requires_grad=True)\n",
        "        self.params = [self.Wx, self.Wh, self.b, self.Wy, self.by]\n",
        "\n",
        "    def forward(self, x_seq):\n",
        "        h = torch.zeros(self.Wh.shape[0])\n",
        "        self.hs = []  # store for BPTT\n",
        "        self.ys = []\n",
        "\n",
        "        for x in x_seq:\n",
        "            h = torch.tanh(x @ self.Wx + h @ self.Wh + self.b)\n",
        "            y_pred = h @ self.Wy + self.by\n",
        "            self.hs.append(h)\n",
        "            self.ys.append(y_pred)\n",
        "        return self.ys\n"
      ],
      "metadata": {
        "id": "pU251CKyctWl"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn = RNNCell(input_size=1, hidden_size=10)\n",
        "lr = 0.01\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "for epoch in range(300):\n",
        "    # Forward\n",
        "    y_preds = rnn.forward(x)\n",
        "    loss = sum(loss_fn(y_pred, target) for y_pred, target in zip(y_preds, y))\n",
        "\n",
        "    # Backward (BPTT)\n",
        "    for p in rnn.params:\n",
        "        if p.grad is not None:\n",
        "            p.grad.zero_()\n",
        "    loss.backward()\n",
        "\n",
        "    # Update weights manually\n",
        "    with torch.no_grad():\n",
        "        for p in rnn.params:\n",
        "            p -= lr * p.grad\n",
        "\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcnlzYu9cvwP",
        "outputId": "5d517ac0-2750-4139-83c8-2a3d2ab86157"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50, Loss: 0.0001\n",
            "Epoch 100, Loss: 0.0000\n",
            "Epoch 150, Loss: 0.0000\n",
            "Epoch 200, Loss: 0.0000\n",
            "Epoch 250, Loss: 0.0000\n",
            "Epoch 300, Loss: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G7VSgIPodemj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}